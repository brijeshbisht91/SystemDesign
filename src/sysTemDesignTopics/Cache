Caching:
 - Caching works on locality of reference principle: recently requested data is likely to be requested again.
 - It's like short-term memory which has limited space but is faster & contains most recently accessed items. 
 - Cache can be used in almost every layer: hardware, OS, Web browsers, web application, but are often found nearest to the front end.
 - Types of cache: 
  - Application server cache:
   - Placing a cache on request layer node enables the local storage of response data. When a request is made, node will quickly return the cached data, if exists. If not it'll query from disk.
   - But when you've many nodes with load balancer, it randomely distribute across the nodes, the same request will go to different noodes, thus increasing cache misses
   - Two choices are to overcome this: global cache & distribute cache.
  - Distribute Cache:
   - In it, each of its nodes own part of cached data. 
   - The cache is divided up using a consitent hashing function, such that if a request node is looking for a certain piece of data, it can quickly know where to look within distributed cache to check if data is available. 
   - Easily we can increase the cache space just by adding nodes to the request pool
  - Global Cache:
   - In this, all nodes use the same single cache space. Each of the request nodes queries the cache in the same way it would a local one.
   - There can two type of global cache:
    - First, when a cached response not found in cache, cache itself becomes responsible for retrieving the missing peice of data. 
    - Second, it's the responsibility of request nodes to retrieve any data that is not found. It can be used when low cache hit % would cause the cache buffer with cache misses. In this situation, it helps to have a large % of data set in cache.
  - CDN
   - It's Content Distribution Network for serving large amount of static media which is common to all. 
   - First request ask the CDN for data, if not cdn will query the back-end servers & then cache it locally
   - If your system is not that big for CDN, you can serve static media from a seperate subdomain using a lightweight HTTP server like Nginx
 - Cache Invalidation
  - When data is modified in DB, it should be invalidated in the cache. 
   - write-through cache: 
    - Data is written into the cache & the DB at the same time.
    - This allow cached to be fast
    - Data consitency also there between cache & DB, which make sure nothing get lost in case of power failure
    - This minimizes the risk of data loss, but has disadvantage of higher latency for write operations.
   - write-around cache: 
    - Data is written directly to storage, bypassing the cache. 
    - This reduces flooded write operations but has disadvantage that a read request for recently written data will create a cache miss & must be read from slower back-end.
   - write-back cache:
    - Data is written to cache alone & completion is immedialtely confirm to client & write to permanent storage is done after specified intervals. 
    - This results in low latency & high throughput, however this spped comes with the risk of data loss in case of crash.
 - Cache eviction policy
  - FIFO
  - LIFO
  - LRU (Least Recently Used): Implement using Doubly Linked list & a hash function containing the reference of node in list
  - Most Recently Used
  - Least frequently Used
  - Random Replacement